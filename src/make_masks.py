import argparse
import csv
import glob
import os
import sys
from collections import deque
from pathlib import Path

import cv2
import numpy as np
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from tqdm import tqdm

CURRENT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = CURRENT_DIR.parent
SRC_DIR = PROJECT_ROOT / "src"
for p in {PROJECT_ROOT, SRC_DIR}:
    if str(p) not in sys.path:
        sys.path.append(str(p))

from colab_model import UNet  # ê¸°ì¡´ lane_model ëŒ€ì²´
from find_diff import DepartureRatioSample, DepartureWindowStats, summarize_departure_samples


class ResNetSegmentation(nn.Module):
    """Wide ResNet-101 ë°±ë³¸ì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸"""
    def __init__(self, num_classes=1):
        super(ResNetSegmentation, self).__init__()
        # Wide ResNet-101 ë°±ë³¸
        resnet = models.wide_resnet101_2(pretrained=False)
        
        # ë°±ë³¸ ë ˆì´ì–´
        self.conv1 = resnet.conv1
        self.bn1 = resnet.bn1
        self.relu = resnet.relu
        self.maxpool = resnet.maxpool
        self.layer1 = resnet.layer1
        self.layer2 = resnet.layer2
        self.layer3 = resnet.layer3
        self.layer4 = resnet.layer4
        
        # ë””ì½”ë” (ê°„ë‹¨í•œ FPN ìŠ¤íƒ€ì¼)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(2048, 1024, kernel_size=2, stride=2),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, num_classes, kernel_size=1)
        )
        
    def forward(self, x):
        # ì¸ì½”ë”
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        
        # ë””ì½”ë”
        x = self.decoder(x)
        return x


class LaneDepartureAnalyzer:
    def __init__(
        self,
        model_path,
        device='auto',
        threshold=0.5,
        use_resnet=False,
        vehicle_center_x: float | None = 620.0,
    ):
        """
        Args:
            model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            device: ë””ë°”ì´ìŠ¤ ('cuda', 'mps', 'cpu', ë˜ëŠ” 'auto')
            threshold: ì´ì§„í™” ì„ê³„ê°’
            use_resnet: Trueë©´ Wide ResNet ë°±ë³¸ ì‚¬ìš©, Falseë©´ UNet ì‚¬ìš©
        """
        if device == 'auto':
            if torch.cuda.is_available():
                self.device = torch.device('cuda')
            elif torch.backends.mps.is_available():
                self.device = torch.device('mps')
            else:
                self.device = torch.device('cpu')
        else:
            self.device = torch.device(device)
        
        # ëª¨ë¸ ë¡œë“œ
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # ëª¨ë¸ íƒ€ì… ìë™ ê°ì§€ (Wide ResNetì¸ì§€ í™•ì¸)
        is_resnet_model = False
        if isinstance(checkpoint, dict):
            keys = list(checkpoint.keys())
            # Wide ResNet íŠ¹ì§• í‚¤ í™•ì¸
            if any('layer1' in k or 'layer2' in k or 'layer3' in k or 'layer4' in k for k in keys):
                is_resnet_model = True
        elif isinstance(checkpoint, torch.nn.Module):
            # ëª¨ë¸ êµ¬ì¡° í™•ì¸
            if hasattr(checkpoint, 'layer1') or hasattr(checkpoint, 'layer4'):
                is_resnet_model = True
        
        # ëª¨ë¸ ìƒì„±
        if is_resnet_model or use_resnet:
            print("Wide ResNet-101 ë°±ë³¸ ëª¨ë¸ ì‚¬ìš©")
            self.model = ResNetSegmentation(num_classes=1)
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            if isinstance(checkpoint, dict):
                # ë°±ë³¸ ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ (ì„¸ê·¸ë©˜í…Œì´ì…˜ í—¤ë”ëŠ” ì œì™¸)
                model_dict = self.model.state_dict()
                pretrained_dict = {}
                
                for k, v in checkpoint.items():
                    # ë°±ë³¸ ë ˆì´ì–´ë§Œ í•„í„°ë§
                    if 'decoder' not in k and 'fc' not in k:
                        # í‚¤ ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
                        if k in model_dict:
                            pretrained_dict[k] = v
                        # conv1, bn1 ë“± ì§ì ‘ ë§¤ì¹­
                        elif k.startswith('conv1.') or k.startswith('bn1.'):
                            pretrained_dict[k] = v
                        elif any(k.startswith(f'{layer}.') for layer in ['layer1', 'layer2', 'layer3', 'layer4']):
                            pretrained_dict[k] = v
                
                # ê°€ì¤‘ì¹˜ ë¡œë“œ
                model_dict.update(pretrained_dict)
                try:
                    self.model.load_state_dict(model_dict, strict=False)
                    print(f"ë°±ë³¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ ({len(pretrained_dict)}ê°œ ë ˆì´ì–´)")
                except Exception as e:
                    print(f"ë°±ë³¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘ ì¼ë¶€ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
                    # ë¶€ë¶„ ë¡œë“œ ì‹œë„
                    try:
                        self.model.load_state_dict(pretrained_dict, strict=False)
                    except:
                        print("ë°±ë³¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨, ëœë¤ ì´ˆê¸°í™”ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©")
            else:
                print("ì²´í¬í¬ì¸íŠ¸ê°€ dict í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ëª¨ë¸ êµ¬ì¡° í™•ì¸ í•„ìš”.")
        else:
            print("UNet ëª¨ë¸ ì‚¬ìš©")
            self.model = UNet(n_channels=3, n_classes=1, bilinear=True)
            
            # ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ í™•ì¸ ë° ë¡œë“œ
            if isinstance(checkpoint, dict):
                if 'model_state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['model_state_dict'])
                elif 'model_state' in checkpoint:
                    self.model.load_state_dict(checkpoint['model_state'])
                elif 'state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['state_dict'])
                else:
                    try:
                        self.model.load_state_dict(checkpoint)
                    except Exception as e:
                        print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ (state_dict í˜•ì‹ ë¶ˆì¼ì¹˜): {e}")
                        print(f"ì²´í¬í¬ì¸íŠ¸ í‚¤: {list(checkpoint.keys())[:10] if len(checkpoint.keys()) > 0 else 'empty'}")
                        raise
            else:
                if isinstance(checkpoint, torch.nn.Module):
                    self.model = checkpoint
                else:
                    print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì²´í¬í¬ì¸íŠ¸ í˜•ì‹: {type(checkpoint)}")
                    raise ValueError("ëª¨ë¸ íŒŒì¼ í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        self.model = self.model.to(self.device)
        self.model.eval()
        
        # ì´ë¯¸ì§€ ë³€í™˜
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        self.threshold = threshold
        self.vehicle_center_x = vehicle_center_x
        
        print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        print(f"ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"ì„ê³„ê°’: {threshold}")
    
    @torch.no_grad()
    def predict_mask(self, image_rgb, threshold=None):
        """
        ì´ë¯¸ì§€ì—ì„œ ì°¨ì„  ë§ˆìŠ¤í¬ ì˜ˆì¸¡
        
        Args:
            image_rgb: RGB í˜•ì‹ì˜ numpy array
            threshold: ì´ì§„í™” ì„ê³„ê°’ (Noneì´ë©´ self.threshold ì‚¬ìš©)
            
        Returns:
            mask: ì°¨ì„  ë§ˆìŠ¤í¬ (0 ë˜ëŠ” 255)
        """
        if threshold is None:
            threshold = self.threshold
            
        pil_image = Image.fromarray(image_rgb)
        h, w = image_rgb.shape[:2]
        image_tensor = self.transform(pil_image).unsqueeze(0).to(self.device)
        
        output = self.model(image_tensor)
        prediction = torch.sigmoid(output).squeeze().cpu().numpy()
        
        # ì¶œë ¥ í¬ê¸°ê°€ ì›ë³¸ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        if prediction.shape != (h, w):
            prediction = cv2.resize(prediction, (w, h), interpolation=cv2.INTER_LINEAR)
        
        # ì´ì§„í™”
        mask = (prediction > threshold).astype(np.uint8) * 255
        
        return mask
    
    def postprocess_mask(self, mask: np.ndarray, bottom_ratio: float = 0.0,
                         roi_mask: np.ndarray | None = None) -> np.ndarray:
        """ì˜ˆì¸¡ëœ ë§ˆìŠ¤í¬ì— í•˜ë‹¨ ì œê±° ë° ROI ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•œë‹¤."""
        processed = mask
        if bottom_ratio > 0:
            processed = self.remove_bottom_region(processed, bottom_ratio=bottom_ratio)
        if roi_mask is not None:
            processed = apply_roi_mask(processed, roi_mask)
        return processed
    
    def analyze_rgb(self, image_rgb: np.ndarray, depart_thr: float = None,
                    bottom_ratio: float = 0.0,
                    roi_mask: np.ndarray | None = None) -> dict:
        """RGB ì´ë¯¸ì§€ ë°°ì—´ ê¸°ë°˜ ì°¨ì„  ë¶„ì„."""
        if depart_thr is None:
            depart_thr = self.threshold
        mask = self.predict_mask(image_rgb)
        processed_mask = self.postprocess_mask(mask, bottom_ratio=bottom_ratio, roi_mask=roi_mask)
        return self._collect_metrics(image_rgb, processed_mask, depart_thr)
    
    def _collect_metrics(self, image_rgb: np.ndarray, mask: np.ndarray,
                         depart_thr: float) -> dict:
        h, w = image_rgb.shape[:2]
        lane_center_x, lane_width, left_x, right_x, both_sides = self.compute_lane_center_and_width(mask)
        
        if self.vehicle_center_x is None:
            vehicle_center_x = w / 2.0
        else:
            vehicle_center_x = float(np.clip(self.vehicle_center_x, 0.0, w - 1))
        vehicle_center_x = float(vehicle_center_x)
        
        norm_offset = None
        departed = False
        left_departed = False
        right_departed = False
        left_ratio = 0.0
        right_ratio = 0.0
        offset_px = None
        
        if lane_center_x is not None:
            offset_px = lane_center_x - vehicle_center_x
            if lane_width is None:
                denom = max(1.0, (w / 2.0))
            else:
                denom = max(1.0, lane_width / 2.0)
            norm_offset = float(abs(offset_px) / denom)
            departed = norm_offset > depart_thr
            ratio_pct = norm_offset * 100.0
            if offset_px < 0:
                left_ratio = ratio_pct
            elif offset_px > 0:
                right_ratio = ratio_pct
        
        if left_x is not None:
            left_departed = vehicle_center_x < left_x
        if right_x is not None:
            right_departed = vehicle_center_x > right_x
        
        return {
            'image_rgb': image_rgb,
            'mask': mask,
            'width': w,
            'height': h,
            'lane_center_x': lane_center_x,
            'lane_width': lane_width,
            'left_x': left_x,
            'right_x': right_x,
            'norm_offset': norm_offset,
            'departed': departed,
            'left_departed': left_departed,
            'right_departed': right_departed,
            'both_sides_detected': both_sides,
            'left_ratio': left_ratio,
            'right_ratio': right_ratio,
            'vehicle_center_x': vehicle_center_x,
            'offset_px': offset_px,
        }
    
    def remove_bottom_region(self, mask, bottom_ratio=0.3):
        """
        ë§ˆìŠ¤í¬ì˜ ì•„ë˜ ì˜ì—­ì„ ì œê±° (ì°¨ëŸ‰ì´ ì°¨ì„ ìœ¼ë¡œ ì¸ì‹ë˜ëŠ” ê²ƒì„ ë°©ì§€)
        
        Args:
            mask: ì°¨ì„  ë§ˆìŠ¤í¬
            bottom_ratio: ì œê±°í•  ì•„ë˜ ì˜ì—­ ë¹„ìœ¨ (0.3 = 30%)
            
        Returns:
            mask: ì•„ë˜ ì˜ì—­ì´ ì œê±°ëœ ë§ˆìŠ¤í¬
        """
        h, w = mask.shape
        bottom_start = int(h * (1 - bottom_ratio))
        
        # ì•„ë˜ 30% ì˜ì—­ì„ 0ìœ¼ë¡œ ì„¤ì •
        mask_cleaned = mask.copy()
        mask_cleaned[bottom_start:, :] = 0
        
        return mask_cleaned
    
    def compute_lane_center_and_width(self, mask, roi_y_ratio=0.7, band_px=30):
        """
        ì´ì§„ ë§ˆìŠ¤í¬ì—ì„œ ì°¨ì„  ì¤‘ì‹¬ê³¼ í­ ê³„ì‚°
        
        Args:
            mask: ì°¨ì„  ë§ˆìŠ¤í¬
            roi_y_ratio: ROI y ë¹„ìœ¨ (0.7 = ìƒìœ„ 70% ì˜ì—­ ì‚¬ìš©, ì•„ë˜ 30%ëŠ” ì´ë¯¸ ì œê±°ë¨)
            band_px: ë¶„ì„í•  ë°´ë“œ í”½ì…€ ìˆ˜
            
        Returns:
            lane_center_x: ì°¨ì„  ì¤‘ì‹¬ xì¢Œí‘œ (ì—†ìœ¼ë©´ None)
            lane_width: ì°¨ì„  í­ (ì—†ìœ¼ë©´ None)
            left_x: ì™¼ìª½ ì°¨ì„  xì¢Œí‘œ (ì—†ìœ¼ë©´ None)
            right_x: ì˜¤ë¥¸ìª½ ì°¨ì„  xì¢Œí‘œ (ì—†ìœ¼ë©´ None)
            both_sides: ì¢Œìš° ì°¨ì„ ì´ ëª¨ë‘ ê²€ì¶œë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
        """
        h, w = mask.shape
        # ROIëŠ” ìƒìœ„ 70% ì˜ì—­ì—ì„œë§Œ (ì•„ë˜ 30%ëŠ” ì´ë¯¸ ì œê±°ë¨)
        y = int(h * roi_y_ratio)
        y0 = max(0, y - band_px)
        y1 = min(h - 1, y + band_px)
        
        band = (mask[y0:y1 + 1] > 0).astype(np.uint8)
        if band.sum() == 0:
            return None, None, None, None, False
        
        # xë³„ë¡œ í”½ì…€ ì¹´ìš´íŠ¸
        x_hist = band.sum(axis=0)
        mid = w // 2
        left_hist = x_hist[:mid]
        right_hist = x_hist[mid:]
        
        left_present = left_hist.sum() > 0
        right_present = right_hist.sum() > 0
        
        left_x = None
        right_x = None
        if left_present:
            xs = np.arange(0, mid)
            left_x = float((xs * left_hist).sum() / max(1, left_hist.sum()))
        if right_present:
            xs = np.arange(mid, w)
            right_x = float((xs * right_hist).sum() / max(1, right_hist.sum()))
        
        if left_present and right_present:
            lane_center_x = (left_x + right_x) / 2.0
            lane_width = max(1.0, right_x - left_x)
            return lane_center_x, lane_width, left_x, right_x, True
        
        # í•œìª½ë§Œ ìˆì„ ë•Œ
        if left_present or right_present:
            xs = np.arange(0, w)
            lane_center_x = float((xs * x_hist).sum() / max(1, x_hist.sum()))
            lane_width = None
            return lane_center_x, lane_width, left_x, right_x, False
        
        return None, None, None, None, False
    
    def analyze_image(self, image_path, depart_thr=0.5, bottom_ratio=0.3,
                      roi_mask: np.ndarray | None = None):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            depart_thr: ì°¨ì„  ì´íƒˆ íŒë‹¨ ì„ê³„ê°’ (norm_offset > depart_thrì´ë©´ ì´íƒˆ)
            
        Returns:
            dict: ë¶„ì„ ê²°ê³¼
        """
        # ì´ë¯¸ì§€ ë¡œë“œ
        image_path = Path(image_path)
        image_path_str = str(image_path)
        img_bgr = cv2.imread(image_path_str, cv2.IMREAD_COLOR)
        if img_bgr is None:
            raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        h, w = img_rgb.shape[:2]
        
        result = self.analyze_rgb(
            img_rgb,
            depart_thr=depart_thr,
            bottom_ratio=bottom_ratio,
            roi_mask=roi_mask,
        )
        result.update({
            'image_path': image_path_str,
            'image_name': image_path.name,
        })
        return result
    
    def draw_overlay(self, image_rgb, mask, lane_center_x, lane_width, left_x, right_x, 
                     norm_offset, departed, left_departed, right_departed,
                     left_departure_rate=None, right_departure_rate=None, total_departure_rate=None,
                     car_center_x: float | None = None,
                     per_frame_left_ratio: float | None = None,
                     per_frame_right_ratio: float | None = None,
                     window_stats: DepartureWindowStats | None = None):
        """
        ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„± (ì°¨ì„  í‘œì‹œ ë° í†µê³„ ì •ë³´)
        
        Args:
            image_rgb: ì›ë³¸ RGB ì´ë¯¸ì§€
            mask: ì°¨ì„  ë§ˆìŠ¤í¬
            lane_center_x: ì°¨ì„  ì¤‘ì‹¬ xì¢Œí‘œ
            lane_width: ì°¨ì„  í­
            left_x: ì™¼ìª½ ì°¨ì„  xì¢Œí‘œ
            right_x: ì˜¤ë¥¸ìª½ ì°¨ì„  xì¢Œí‘œ
            norm_offset: ì •ê·œí™”ëœ ì˜¤í”„ì…‹
            departed: ì „ì²´ ì´íƒˆ ì—¬ë¶€
            left_departed: ì™¼ìª½ ì´íƒˆ ì—¬ë¶€
            right_departed: ì˜¤ë¥¸ìª½ ì´íƒˆ ì—¬ë¶€
            left_departure_rate: ì™¼ìª½ ì°¨ì„  ì´íƒˆë¥  (ì „ì²´ í†µê³„ìš©)
            right_departure_rate: ì˜¤ë¥¸ìª½ ì°¨ì„  ì´íƒˆë¥  (ì „ì²´ í†µê³„ìš©)
            total_departure_rate: ì „ì²´ ì°¨ì„  ì´íƒˆë¥  (ì „ì²´ í†µê³„ìš©)
            
        Returns:
            overlay: ì˜¤ë²„ë ˆì´ëœ ì´ë¯¸ì§€ (RGB)
        """
        h, w = image_rgb.shape[:2]
        # RGBë¥¼ BGRë¡œ ë³€í™˜ (OpenCV í•¨ìˆ˜ ì‚¬ìš©ì„ ìœ„í•´)
        overlay = cv2.cvtColor(image_rgb.copy(), cv2.COLOR_RGB2BGR)
        
        # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ (ë¹¨ê°„ìƒ‰) - ê²€ì¶œëœ ì°¨ì„  (BGR ìˆœì„œ: 0, 0, 255)
        # ì°¨ì„  íƒì§€ ì‹œê°í™”ë¥¼ ë” ëª…í™•í•˜ê²Œ í•˜ê¸° ìœ„í•´ ì•½ê°„ ë” ì§„í•˜ê²Œ í‘œì‹œ
        mask_bgr = cv2.cvtColor(image_rgb.copy(), cv2.COLOR_RGB2BGR)
        color_mask = np.zeros_like(mask_bgr)
        color_mask[mask > 0] = [0, 0, 255]  # BGRì—ì„œ ë¹¨ê°„ìƒ‰
        overlay = cv2.addWeighted(overlay, 0.65, color_mask, 0.35, 0)  # ì°¨ì„ ì„ ë” ëª…í™•í•˜ê²Œ í‘œì‹œ
        
        # ì°¨ëŸ‰ ì¤‘ì‹¬ì„  (ë…¸ë€ìƒ‰) - ì‚¬ìš©ìê°€ ì§€ì •í•œ xì¢Œí‘œ
        if car_center_x is None:
            cx_vehicle = w // 2
        else:
            cx_vehicle = int(np.clip(round(car_center_x), 0, w - 1))
        cv2.line(overlay, (cx_vehicle, int(h * 0.6)), (cx_vehicle, h - 1), (0, 255, 255), 3)
        cv2.putText(
            overlay,
            f"Vehicle Center ({cx_vehicle})",
            (max(0, cx_vehicle - 110), int(h * 0.58)),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (0, 255, 255),
            1,
            cv2.LINE_AA,
        )
        
        # ì°¨ì„  ì¤‘ì‹¬ì„  (ì´ˆë¡ìƒ‰) (BGR ìˆœì„œ: 0, 255, 0)
        if lane_center_x is not None:
            cx = int(round(lane_center_x))
            cv2.line(overlay, (cx, int(h * 0.6)), (cx, h - 1), (0, 255, 0), 3)
            cv2.putText(overlay, "Lane Center", (cx - 70, int(h * 0.58)), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)
        
        # ì™¼ìª½ ì°¨ì„  (íŒŒë€ìƒ‰) (BGR ìˆœì„œ: 255, 0, 0)
        if left_x is not None:
            lx = int(round(left_x))
            cv2.line(overlay, (lx, int(h * 0.6)), (lx, h - 1), (255, 0, 0), 2)
            if left_departed:
                cv2.putText(overlay, "LEFT DEPARTED", (lx - 90, int(h * 0.55)), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1, cv2.LINE_AA)
        
        # ì˜¤ë¥¸ìª½ ì°¨ì„  (íŒŒë€ìƒ‰) (BGR ìˆœì„œ: 255, 0, 0)
        if right_x is not None:
            rx = int(round(right_x))
            cv2.line(overlay, (rx, int(h * 0.6)), (rx, h - 1), (255, 0, 0), 2)
            if right_departed:
                cv2.putText(overlay, "RIGHT DEPARTED", (rx - 100, int(h * 0.55)), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1, cv2.LINE_AA)
        
        # ì •ë³´ íŒ¨ë„ (ì˜¤ë¥¸ìª½ ìƒë‹¨)
        info_lines: list[str] = []

        def add_blank():
            if info_lines and info_lines[-1] != "":
                info_lines.append("")
        
        summary_lines = []
        if total_departure_rate is not None:
            summary_lines.append(f"Total: {total_departure_rate:.1f}%")
        if left_departure_rate is not None:
            summary_lines.append(f"Left: {left_departure_rate:.1f}%")
        if right_departure_rate is not None:
            summary_lines.append(f"Right: {right_departure_rate:.1f}%")
        if summary_lines:
            info_lines.extend(summary_lines)
            add_blank()

        if window_stats and window_stats.sample_count > 0:
            info_lines.append(f"Window: {window_stats.sample_count}f")
            info_lines.append(
                f" Avg L: {window_stats.avg_left_ratio:.1f}% | Avg R: {window_stats.avg_right_ratio:.1f}%"
            )
            depart_line = f" Depart: {window_stats.departure_rate:.1f}%"
            if window_stats.dominant_side:
                depart_line += f" ({window_stats.dominant_side})"
            info_lines.append(depart_line)
            add_blank()
        
        # ì´íƒˆ ìƒíƒœ í‘œì‹œ
        status_parts = []
        if left_departed:
            status_parts.append("LEFT DEPARTED")
        if right_departed:
            status_parts.append("RIGHT DEPARTED")
        if not left_departed and not right_departed:
            if departed:
                status_parts.append("DEPARTED")
            else:
                status_parts.append("IN-LANE")
        
        if status_parts:
            info_lines.append(" | ".join(status_parts))
        
        # ì¶”ê°€ ì •ë³´
        if norm_offset is not None:
            info_lines.append(f"Offset: {norm_offset:.3f}")
        if lane_width is not None:
            info_lines.append(f"Width: {lane_width:.0f}px")
        
        if per_frame_left_ratio is not None or per_frame_right_ratio is not None:
            add_blank()
            info_lines.append(f"Frame L: {0.0 if per_frame_left_ratio is None else per_frame_left_ratio:.1f}%")
            info_lines.append(f"Frame R: {0.0 if per_frame_right_ratio is None else per_frame_right_ratio:.1f}%")
        
        # ë°°ê²½ ë°•ìŠ¤ (ì˜¤ë¥¸ìª½ ìƒë‹¨)
        text_height = 22
        box_width = 250
        box_height = len([l for l in info_lines if l]) * text_height + 15
        box_x = w - box_width - 10
        box_y = 10
        
        cv2.rectangle(overlay, (box_x, box_y), (w - 10, box_y + box_height), (0, 0, 0), -1)
        cv2.rectangle(overlay, (box_x, box_y), (w - 10, box_y + box_height), (255, 255, 255), 2)
        
        # í…ìŠ¤íŠ¸ ì¶œë ¥
        y_offset = box_y + 25
        for i, line in enumerate(info_lines):
            if line == "":
                y_offset += text_height // 2
                continue
            if "Total:" in line or "Left:" in line or "Right:" in line:
                color = (0, 255, 255)  # ë…¸ë€ìƒ‰ (BGR) - ì´íƒˆë¥  ê°•ì¡°
                font_scale = 0.55
                thickness = 2
            elif "DEPARTED" in line:
                color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (BGR)
                font_scale = 0.5
                thickness = 2
            elif "IN-LANE" in line:
                color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ (BGR)
                font_scale = 0.5
                thickness = 2
            else:
                color = (255, 255, 255)  # í°ìƒ‰ (BGR)
                font_scale = 0.45
                thickness = 1
            cv2.putText(overlay, line, (box_x + 10, y_offset + i * text_height), 
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness, cv2.LINE_AA)
        
        # ë²”ë¡€ (í•˜ë‹¨)
        legend_y = h - 100
        cv2.rectangle(overlay, (10, legend_y), (450, h - 10), (0, 0, 0), -1)
        cv2.rectangle(overlay, (10, legend_y), (450, h - 10), (255, 255, 255), 2)
        cv2.putText(overlay, "Legend:", (20, legend_y + 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)
        cv2.line(overlay, (25, legend_y + 30), (65, legend_y + 30), (0, 255, 255), 2)  # ë…¸ë€ìƒ‰ (BGR)
        cv2.putText(overlay, "Vehicle Center", (70, legend_y + 35), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1, cv2.LINE_AA)
        cv2.line(overlay, (25, legend_y + 50), (65, legend_y + 50), (0, 255, 0), 2)  # ì´ˆë¡ìƒ‰ (BGR)
        cv2.putText(overlay, "Lane Center", (70, legend_y + 55), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1, cv2.LINE_AA)
        cv2.line(overlay, (25, legend_y + 70), (65, legend_y + 70), (255, 0, 0), 2)  # íŒŒë€ìƒ‰ (BGR)
        cv2.putText(overlay, "Left/Right Lane", (70, legend_y + 75), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1, cv2.LINE_AA)
        
        # BGRì„ RGBë¡œ ë‹¤ì‹œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)


def load_roi_mask(mask_path: Path | None,
                  target_hw: tuple[int, int] | None = None) -> np.ndarray | None:
    if mask_path is None:
        return None
    if not mask_path.exists():
        raise FileNotFoundError(f"ROI ë§ˆìŠ¤í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {mask_path}")
    roi_img = Image.open(mask_path).convert("L")
    if target_hw is not None:
        h, w = target_hw
        if (roi_img.height, roi_img.width) != (h, w):
            roi_img = roi_img.resize((w, h), Image.NEAREST)
    roi_arr = (np.array(roi_img) > 127).astype(np.uint8) * 255
    return roi_arr


def apply_roi_mask(mask: np.ndarray, roi_mask: np.ndarray | None) -> np.ndarray:
    """ROI ë§ˆìŠ¤í¬ë¥¼ ì°¨ì„  ë§ˆìŠ¤í¬ì— ì ìš©."""
    if roi_mask is None:
        return mask
    if roi_mask.shape != mask.shape:
        resized_roi = cv2.resize(
            roi_mask,
            (mask.shape[1], mask.shape[0]),
            interpolation=cv2.INTER_NEAREST,
        )
    else:
        resized_roi = roi_mask
    return cv2.bitwise_and(mask, mask, mask=resized_roi)


def collect_image_files(image_dir: Path, limit: int | None = None) -> list[Path]:
    if not image_dir.exists():
        raise FileNotFoundError(f"ì´ë¯¸ì§€ ë””ë ‰í„°ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
    paths = sorted(
        p for p in image_dir.iterdir()
        if p.is_file() and p.suffix.lower() in {".jpg", ".jpeg", ".png"}
    )
    if not paths:
        raise RuntimeError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
    if limit is not None:
        paths = paths[:limit]
    return paths


def generate_masks_from_dataset(args, analyzer: LaneDepartureAnalyzer,
                                roi_mask: np.ndarray | None) -> None:
    image_dir: Path = args.image_dir.resolve()
    mask_dir: Path = args.mask_dir.resolve()
    answer_dir: Path = args.answer_dir.resolve()

    mask_dir.mkdir(parents=True, exist_ok=True)
    if args.copy_to_answer:
        answer_dir.mkdir(parents=True, exist_ok=True)

    image_paths = collect_image_files(image_dir, args.limit)
    print(f"[INFO] ì´ {len(image_paths)}ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    for idx, img_path in enumerate(tqdm(image_paths, desc="ë§ˆìŠ¤í¬ ìƒì„±"), start=1):
        img_bgr = cv2.imread(str(img_path), cv2.IMREAD_COLOR)
        if img_bgr is None:
            print(f"[WARN] ì´ë¯¸ì§€ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
            continue
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        mask = analyzer.predict_mask(img_rgb)
        mask = analyzer.postprocess_mask(
            mask,
            bottom_ratio=args.bottom_ratio,
            roi_mask=roi_mask,
        )

        mask_filename = f"{img_path.stem}_mask.png"
        mask_output = mask_dir / mask_filename
        Image.fromarray(mask.astype(np.uint8)).save(mask_output)
        if args.copy_to_answer:
            Image.fromarray(mask.astype(np.uint8)).save(answer_dir / mask_filename)

        coverage = mask.sum() / (255 * mask.size)
        print(f"[{idx:04d}/{len(image_paths):04d}] {img_path.name} -> "
              f"{mask_filename} (coverage {coverage:.4f})")

    print("[INFO] ë§ˆìŠ¤í¬ ìƒì„±ì„ ë§ˆì³¤ìŠµë‹ˆë‹¤.")


def generate_overlay_video(args, analyzer: LaneDepartureAnalyzer,
                           roi_mask: np.ndarray | None) -> Path:
    video_path: Path = args.video_path.resolve()
    if not video_path.exists():
        raise FileNotFoundError(f"ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

    if args.video_output is None:
        output_path = PROJECT_ROOT / "outputs" / f"{video_path.stem}_overlay.mp4"
    else:
        output_path = args.video_output.resolve()
    output_path.parent.mkdir(parents=True, exist_ok=True)

    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise RuntimeError(f"ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

    fps = cap.get(cv2.CAP_PROP_FPS)
    if not fps or fps <= 1e-3:
        fps = args.video_fps or 30.0
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    if width <= 0 or height <= 0:
        raise RuntimeError("ì˜ìƒ í•´ìƒë„ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    writer = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
    if not writer.isOpened():
        cap.release()
        raise RuntimeError(f"ì¶œë ¥ ì˜ìƒì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {output_path}")

    window_size = max(1, int(round(fps * args.video_window_sec)))
    ratio_window: deque[DepartureRatioSample] = deque(maxlen=window_size)

    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_limit = args.video_max_frames if args.video_max_frames else None
    progress_total = frame_limit or (total_frames if total_frames > 0 else None)
    processed = 0

    progress = tqdm(total=progress_total, desc="ì˜ìƒ ì²˜ë¦¬", unit="frame")
    try:
        while True:
            ret, frame_bgr = cap.read()
            if not ret:
                break

            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
            frame_result = analyzer.analyze_rgb(
                frame_rgb,
                depart_thr=args.threshold,
                bottom_ratio=args.bottom_ratio,
                roi_mask=roi_mask,
            )

            ratio_window.append(
                DepartureRatioSample(
                    left_ratio=frame_result['left_ratio'],
                    right_ratio=frame_result['right_ratio'],
                    departed=frame_result['departed'],
                )
            )
            window_stats = summarize_departure_samples(ratio_window)

            overlay_rgb = analyzer.draw_overlay(
                image_rgb=frame_result['image_rgb'],
                mask=frame_result['mask'],
                lane_center_x=frame_result['lane_center_x'],
                lane_width=frame_result['lane_width'],
                left_x=frame_result['left_x'],
                right_x=frame_result['right_x'],
                norm_offset=frame_result['norm_offset'],
                departed=frame_result['departed'],
                left_departed=frame_result['left_departed'],
                right_departed=frame_result['right_departed'],
                left_departure_rate=None,
                right_departure_rate=None,
                total_departure_rate=None,
                car_center_x=frame_result['vehicle_center_x'],
                per_frame_left_ratio=frame_result['left_ratio'],
                per_frame_right_ratio=frame_result['right_ratio'],
                window_stats=window_stats,
            )

            writer.write(cv2.cvtColor(overlay_rgb, cv2.COLOR_RGB2BGR))

            processed += 1
            progress.update(1)
            if frame_limit and processed >= frame_limit:
                break
    finally:
        progress.close()
        cap.release()
        writer.release()

    print(f"[INFO] ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ ({processed} frames) â†’ {output_path}")
    return output_path


def parse_mask_cli_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="make_masks.py ê¸°ë°˜ìœ¼ë¡œ data/images â†’ data/masks(+answer) ë§ˆìŠ¤í¬ ìƒì„±"
    )
    parser.add_argument("--image-dir", type=Path, default=PROJECT_ROOT / "data" / "images")
    parser.add_argument("--mask-dir", type=Path, default=PROJECT_ROOT / "data" / "masks")
    parser.add_argument("--answer-dir", type=Path, default=PROJECT_ROOT / "data" / "answer")
    parser.add_argument("--model-path", type=Path, default=PROJECT_ROOT / "model" / "lane_detect.pth")
    parser.add_argument("--roi-mask", type=Path, default=PROJECT_ROOT / "data" / "masks" / "masked.png")
    parser.add_argument("--disable-roi", action="store_true", help="ROI ë§ˆìŠ¤í¬ ì ìš© ì•ˆ í•¨")
    parser.add_argument("--threshold", type=float, default=0.5)
    parser.add_argument("--bottom-ratio", type=float, default=0.3,
                        help="ì•„ë˜ìª½ ì œê±° ë¹„ìœ¨ (0ì´ë©´ ë¯¸ì ìš©)")
    parser.add_argument("--device", default="auto", choices=["auto", "cuda", "cpu", "mps"])
    parser.add_argument("--limit", type=int, default=None, help="ì²˜ë¦¬í•  ì´ë¯¸ì§€ ìˆ˜ ì œí•œ")
    parser.add_argument("--copy-to-answer", action="store_true",
                        help="ìƒì„±ëœ ë§ˆìŠ¤í¬ë¥¼ answer ë””ë ‰í„°ë¦¬ì—ë„ ë³µì‚¬")
    parser.add_argument("--use-resnet", action="store_true",
                        help="Wide ResNet ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ ì‹œë„")
    parser.add_argument("--car-center-x", type=float, default=620.0,
                        help="ì˜¤ë²„ë ˆì´ì— ì‚¬ìš©í•  ì°¨ëŸ‰ ì¤‘ì‹¬ X ì¢Œí‘œ")
    parser.add_argument("--video-path", type=Path, default=None,
                        help="ì°¨ì„  ì´íƒˆë¥  ì˜¤ë²„ë ˆì´ë¥¼ ìƒì„±í•  ì…ë ¥ ì˜ìƒ ê²½ë¡œ")
    parser.add_argument("--video-output", type=Path, default=None,
                        help="ì˜¤ë²„ë ˆì´ ê²°ê³¼ ì˜ìƒì„ ì €ì¥í•  ê²½ë¡œ (ê¸°ë³¸: outputs/<ì´ë¦„>_overlay.mp4)")
    parser.add_argument("--video-window-sec", type=float, default=2.0,
                        help="ì‹¤ì‹œê°„ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìœ„í•œ ì°¨ì„  ì´íƒˆë¥  ìœˆë„ ê¸¸ì´(ì´ˆ)")
    parser.add_argument("--video-max-frames", type=int, default=None,
                        help="ë””ë²„ê¹…ìš©: ì²˜ë¦¬í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜")
    parser.add_argument("--video-fps", type=float, default=None,
                        help="ì˜ìƒ ë©”íƒ€ë°ì´í„°ì— FPSê°€ ì—†ì„ ê²½ìš° ì‚¬ìš©í•  ê°’")
    parser.add_argument("--video-only", action="store_true",
                        help="ë§ˆìŠ¤í¬ ìƒì„±ì€ ê±´ë„ˆë›°ê³  ì˜ìƒ ì˜¤ë²„ë ˆì´ë§Œ ìƒì„±")
    return parser.parse_args()


def mask_generation_cli():
    args = parse_mask_cli_args()
    roi_mask = None
    if not args.disable_roi and args.roi_mask is not None:
        roi_mask = load_roi_mask(args.roi_mask, None)

    analyzer = LaneDepartureAnalyzer(
        model_path=str(args.model_path.resolve()),
        device=args.device,
        threshold=args.threshold,
        use_resnet=args.use_resnet,
        vehicle_center_x=args.car_center_x,
    )

    if not args.video_only:
        generate_masks_from_dataset(args, analyzer, roi_mask)
    if args.video_path:
        args.video_path = args.video_path.expanduser().resolve()
        if args.video_output:
            args.video_output = args.video_output.expanduser()
        generate_overlay_video(args, analyzer, roi_mask)
    elif args.video_only:
        print("[WARN] --video-only ì˜µì…˜ì´ ì§€ì •ë˜ì—ˆì§€ë§Œ --video-path ê°€ ì—†ì–´ ì‹¤í–‰í•  ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")


def lane_departure_analysis_report():
    # ì„¤ì •
    image_dir = "/Users/joonseokim/Desktop/ìº¡ìŠ¤í†¤ì˜ìƒ_11_16/drive-download-20251117T145515Z-1-001/drive-download-20251117T145515Z-1-001_frames"
    model_path = "/Users/joonseokim/Downloads/wide_resnet101_2-32ee1156.pth"
    output_dir = "./11_16_lane_detection_results"
    
    # ëª¨ë¸ íŒŒì¼ í™•ì¸
    if not os.path.exists(model_path):
        print(f"ì—ëŸ¬: ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return
    
    # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ í™•ì¸
    if not os.path.exists(image_dir):
        print(f"ì—ëŸ¬: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        return
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
    image_files = sorted(glob.glob(os.path.join(image_dir, "*.jpg")) + 
                        glob.glob(os.path.join(image_dir, "*.png")))
    
    if not image_files:
        print(f"ì—ëŸ¬: ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        return
    
    print(f"ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    print(f"ëª¨ë¸: {model_path}")
    print(f"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {image_dir}")
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    print("-" * 60)
    
    # ë¶„ì„ê¸° ìƒì„±
    analyzer = LaneDepartureAnalyzer(model_path, device='auto', threshold=0.5)
    
    # detected í´ë” ìƒì„±
    detected_dir = os.path.join(output_dir, 'detected')
    os.makedirs(detected_dir, exist_ok=True)
    
    # ê²°ê³¼ ì €ì¥ìš©
    results = []
    departed_count = 0
    left_departed_count = 0
    right_departed_count = 0
    images_with_lanes = []  # ì°¨ì„ ì´ íƒì§€ëœ ì´ë¯¸ì§€ë“¤
    
    # ì²« ë²ˆì§¸ íŒ¨ìŠ¤: ì´ë¯¸ì§€ ë¶„ì„
    print("\n1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
    for img_path in tqdm(image_files, desc="ì²˜ë¦¬ ì¤‘"):
        try:
            result = analyzer.analyze_image(img_path, depart_thr=0.5)
            
            if result['departed']:
                departed_count += 1
            if result['left_departed']:
                left_departed_count += 1
            if result['right_departed']:
                right_departed_count += 1
            
            # ì°¨ì„ ì´ íƒì§€ëœ ì´ë¯¸ì§€ë§Œ ì €ì¥
            if result['lane_center_x'] is not None:
                images_with_lanes.append(result)
            
            results.append({
                'image_name': result['image_name'],
                'image_path': result['image_path'],
                'width': result['width'],
                'height': result['height'],
                'lane_center_x': '' if result['lane_center_x'] is None else f"{result['lane_center_x']:.2f}",
                'lane_width_px': '' if result['lane_width'] is None else f"{result['lane_width']:.1f}",
                'left_x': '' if result['left_x'] is None else f"{result['left_x']:.2f}",
                'right_x': '' if result['right_x'] is None else f"{result['right_x']:.2f}",
                'norm_offset': '' if result['norm_offset'] is None else f"{result['norm_offset']:.3f}",
                'departed': int(result['departed']),
                'left_departed': int(result['left_departed']),
                'right_departed': int(result['right_departed']),
                'both_sides_detected': int(result['both_sides_detected']),
            })
        except Exception as e:
            print(f"\nì—ëŸ¬ ë°œìƒ ({os.path.basename(img_path)}): {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # í†µê³„ ê³„ì‚°
    total_images = len(results)
    departure_rate = departed_count / total_images if total_images > 0 else 0.0
    
    # ì™¼ìª½/ì˜¤ë¥¸ìª½ ì´íƒˆë¥  ê³„ì‚° (ì°¨ì„ ì´ íƒì§€ëœ ì´ë¯¸ì§€ë§Œ ëŒ€ìƒ)
    left_departed_lane_count = sum(1 for r in images_with_lanes if r['left_departed'])
    right_departed_lane_count = sum(1 for r in images_with_lanes if r['right_departed'])
    total_with_lanes = len(images_with_lanes)
    
    left_departure_rate = (left_departed_lane_count / total_with_lanes * 100) if total_with_lanes > 0 else 0.0
    right_departure_rate = (right_departed_lane_count / total_with_lanes * 100) if total_with_lanes > 0 else 0.0
    total_departure_rate = departure_rate * 100
    
    # norm_offset í†µê³„
    norm_offsets = [float(r['norm_offset']) for r in results if r['norm_offset'] and r['norm_offset'] != '']
    avg_offset = sum(norm_offsets) / len(norm_offsets) if norm_offsets else 0.0
    max_offset = max(norm_offsets) if norm_offsets else 0.0
    min_offset = min(norm_offsets) if norm_offsets else 0.0
    
    # ë‘ ë²ˆì§¸ íŒ¨ìŠ¤: ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥
    print(f"\n2ë‹¨ê³„: ì°¨ì„  íƒì§€ëœ ì´ë¯¸ì§€ ì˜¤ë²„ë ˆì´ ìƒì„± ë° ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ ì¤‘... ({len(images_with_lanes)}ê°œ)")
    for result in tqdm(images_with_lanes, desc="ì´ë¯¸ì§€ ì €ì¥ ì¤‘"):
        try:
            # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±
            overlay = analyzer.draw_overlay(
                result['image_rgb'],
                result['mask'],
                result['lane_center_x'],
                result['lane_width'],
                result['left_x'],
                result['right_x'],
                result['norm_offset'],
                result['departed'],
                result['left_departed'],
                result['right_departed'],
                left_departure_rate,
                right_departure_rate,
                total_departure_rate
            )
            
            # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ì €ì¥
            overlay_bgr = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)
            overlay_path = os.path.join(detected_dir, f"overlay_{result['image_name']}")
            cv2.imwrite(overlay_path, overlay_bgr)
            
            # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
            original_bgr = cv2.cvtColor(result['image_rgb'], cv2.COLOR_RGB2BGR)
            original_path = os.path.join(detected_dir, f"original_{result['image_name']}")
            cv2.imwrite(original_path, original_bgr)
        except Exception as e:
            print(f"\nì´ë¯¸ì§€ ì €ì¥ ì—ëŸ¬ ({result['image_name']}): {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # CSV ì €ì¥
    csv_path = os.path.join(output_dir, 'lane_departure_results.csv')
    if results:
        with open(csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=results[0].keys())
            writer.writeheader()
            writer.writerows(results)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 70)
    print(" " * 20 + "ì°¨ì„  ì´íƒˆë¥  ë¶„ì„ ê²°ê³¼")
    print("=" * 70)
    print(f"  ğŸ“Š ì´ ë¶„ì„ ì´ë¯¸ì§€:       {total_images}ê°œ")
    print(f"  ğŸ” ì°¨ì„  íƒì§€ëœ ì´ë¯¸ì§€:   {total_with_lanes}ê°œ")
    print()
    print(f"  ğŸ“ˆ ì „ì²´ ì°¨ì„  ì´íƒˆë¥ :     {total_departure_rate:.2f}%")
    print(f"     - ì°¨ì„  ë‚´ ì£¼í–‰:       {total_images - departed_count}ê°œ ({(total_images - departed_count)/total_images*100:.1f}%)")
    print(f"     - ì°¨ì„  ì´íƒˆ:           {departed_count}ê°œ ({departed_count/total_images*100:.1f}%)")
    print()
    print(f"  â¬…ï¸  ì™¼ìª½ ì°¨ì„  ì´íƒˆë¥ :     {left_departure_rate:.2f}%")
    print(f"     - ì™¼ìª½ ì´íƒˆ:           {left_departed_lane_count}ê°œ / {total_with_lanes}ê°œ")
    print()
    print(f"  â¡ï¸  ì˜¤ë¥¸ìª½ ì°¨ì„  ì´íƒˆë¥ :   {right_departure_rate:.2f}%")
    print(f"     - ì˜¤ë¥¸ìª½ ì´íƒˆ:         {right_departed_lane_count}ê°œ / {total_with_lanes}ê°œ")
    print()
    if norm_offsets:
        print(f"  ğŸ“ norm_offset í†µê³„:")
        print(f"     - í‰ê· : {avg_offset:.3f}")
        print(f"     - ìµœì†Œ: {min_offset:.3f}")
        print(f"     - ìµœëŒ€: {max_offset:.3f}")
    print()
    print(f"  ğŸ“ ê²°ê³¼ íŒŒì¼:")
    print(f"     - CSV ê²°ê³¼:        {csv_path}")
    print(f"     - ì›ë³¸ ì´ë¯¸ì§€:     {detected_dir}/original_*.jpg (ì´ {len(images_with_lanes)}ê°œ)")
    print(f"     - ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€: {detected_dir}/overlay_*.jpg (ì´ {len(images_with_lanes)}ê°œ)")
    print()
    print("  ğŸ“Œ ì£¼ìš” ì§€í‘œ ì„¤ëª…:")
    print("     - ì „ì²´ ì°¨ì„  ì´íƒˆë¥ : norm_offset ê¸°ì¤€ ì´íƒˆ ì´ë¯¸ì§€ ë¹„ìœ¨")
    print("     - ì™¼ìª½/ì˜¤ë¥¸ìª½ ì´íƒˆë¥ : ê° ì°¨ì„  ê¸°ì¤€ ì´íƒˆ ì´ë¯¸ì§€ ë¹„ìœ¨ (ì°¨ì„  íƒì§€ëœ ì´ë¯¸ì§€ë§Œ ëŒ€ìƒ)")
    print("     - norm_offset: ì°¨ì„  ì¤‘ì‹¬ê³¼ ì°¨ëŸ‰ ì¤‘ì‹¬ì˜ ì •ê·œí™”ëœ ê±°ë¦¬")
    print("       * 0.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì°¨ì„  ì¤‘ì•™ì— ìœ„ì¹˜")
    print("       * 0.5 ì´ìƒì´ë©´ ì´íƒˆë¡œ íŒë‹¨")
    print("     - ì•„ë˜ 30% ì˜ì—­ì€ ì°¨ì„  íƒì§€ì—ì„œ ì œì™¸ë¨ (ì°¨ëŸ‰ ë°©ì§€)")
    print("=" * 70)
    
    # ì´ë¯¸ì§€ë³„ ìƒì„¸ ê²°ê³¼ ì¶œë ¥ (ì²˜ìŒ 10ê°œ, ì°¨ì„  íƒì§€ëœ ê²ƒë§Œ)
    detected_results = [r for r in results if r['lane_center_x']]
    print(f"\nì°¨ì„  íƒì§€ëœ ì´ë¯¸ì§€ë³„ ìƒì„¸ ê²°ê³¼ (ì²˜ìŒ 10ê°œ / ì´ {len(detected_results)}ê°œ):")
    print("-" * 90)
    print(f"{'ì´ë¯¸ì§€ëª…':<35} {'norm_offset':<12} {'ì™¼ìª½':<8} {'ì˜¤ë¥¸ìª½':<8} {'ì „ì²´':<8}")
    print("-" * 90)
    for i, r in enumerate(detected_results[:10]):
        offset_str = r['norm_offset'] if r['norm_offset'] else "N/A"
        left_status = "ì´íƒˆ" if r['left_departed'] else "ì •ìƒ"
        right_status = "ì´íƒˆ" if r['right_departed'] else "ì •ìƒ"
        total_status = "ì´íƒˆ" if r['departed'] else "ì •ìƒ"
        print(f"{r['image_name']:<35} {offset_str:<12} {left_status:<8} {right_status:<8} {total_status:<8}")
    
    if len(detected_results) > 10:
        print(f"... ì™¸ {len(detected_results) - 10}ê°œ ì´ë¯¸ì§€ (ì „ì²´ ê²°ê³¼ëŠ” CSV íŒŒì¼ ì°¸ì¡°)")


if __name__ == '__main__':
    mask_generation_cli()

